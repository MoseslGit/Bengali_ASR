{"cells":[{"cell_type":"markdown","metadata":{},"source":["We trained the \"facebook/wav2vec2-large-xlsr-53\" model on our pre-processed data. The training was done in 12 hour sessions for about 50 hours in total. For each session, the model of the the last session was loaded and trained further. We decided not to train from the last checkpoint since we found AdamW learning rates to be untenably low after each session.\n","\n","Relevant models can be found at : https://huggingface.co/Sameen53\n","Relevant pre-processed data can be found at: https://huggingface.co/Lancelot53\n"]},{"cell_type":"markdown","metadata":{},"source":["Edit: September 1, 2022\n","\n","First phase of training started with facebook/wav2vec2-large-xlsr-53 as base. Trained on 36919 samples from the train set (upvotes>downvotes and between 1 and 10s, can be found on PreProcessing1 notebook). Trained for 71 epochs. Final model saved as Sameen53/cv_bn_bestModel_1\n","\n","\n","Second phase of training with Sameen53/cv_bn_bestModel_1 as base. Trained on about 45k data collected from train set and validation set combined (can be found on PreProcessing2 notebook)"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-08-14T05:58:47.353715Z","iopub.status.busy":"2022-08-14T05:58:47.353213Z","iopub.status.idle":"2022-08-14T05:59:15.675229Z","shell.execute_reply":"2022-08-14T05:59:15.673938Z","shell.execute_reply.started":"2022-08-14T05:58:47.353623Z"},"id":"li1wWFsGdt2x","papermill":{"duration":27.015792,"end_time":"2022-08-12T04:45:31.621232","exception":false,"start_time":"2022-08-12T04:45:04.605440","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# # %%capture\n","# # !apt install git-lfs\n","# # !pip install transformers\n","# %pip install jiwer\n","# %pip install python-dotenv\n","# %pip install transformers[torch]\n","# %pip install accelerate -U"]},{"cell_type":"code","execution_count":147,"metadata":{},"outputs":[],"source":["import torch\n","from transformers import Wav2Vec2Processor\n","from dataclasses import dataclass, field\n","from typing import Any, Dict, List, Optional, Union"]},{"cell_type":"code","execution_count":148,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["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\n"]}],"source":["import os\n","from dotenv import load_dotenv\n","\n","load_dotenv()\n","hugging_face_token = os.getenv('hugging_face_token')\n","print(hugging_face_token)"]},{"cell_type":"code","execution_count":149,"metadata":{"execution":{"iopub.execute_input":"2022-08-12T04:45:31.631617Z","iopub.status.busy":"2022-08-12T04:45:31.630598Z","iopub.status.idle":"2022-08-12T04:45:34.045166Z","shell.execute_reply":"2022-08-12T04:45:34.044207Z"},"id":"z3uqOz7C6SPH","papermill":{"duration":2.422092,"end_time":"2022-08-12T04:45:34.047525","exception":false,"start_time":"2022-08-12T04:45:31.625433","status":"completed"},"tags":[]},"outputs":[],"source":["# pad features to get tensors of the same size\n","# loss from the padded labels is ignored during training\n","\n","@dataclass\n","class DataCollatorCTCWithPadding:\n","\n","    processor: Wav2Vec2Processor\n","    padding: Union[bool, str] = True\n","\n","    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n","        # split inputs and labels since they have to be of different lenghts and need\n","        # different padding methods\n","        input_features = [{\"input_values\": feature[\"input_values\"]} for feature in features]\n","        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n","\n","        batch = self.processor.pad(\n","            input_features,\n","            padding=self.padding,\n","            return_tensors=\"pt\",\n","        )\n","        with self.processor.as_target_processor():\n","            labels_batch = self.processor.pad(\n","                label_features,\n","                padding=self.padding,\n","                return_tensors=\"pt\",\n","            )\n","\n","        # replace padding with -100 to ignore loss correctly\n","        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n","\n","        batch[\"labels\"] = labels\n","\n","        return batch"]},{"cell_type":"code","execution_count":150,"metadata":{"execution":{"iopub.execute_input":"2022-08-14T06:00:51.923747Z","iopub.status.busy":"2022-08-14T06:00:51.923323Z","iopub.status.idle":"2022-08-14T06:01:10.464053Z","shell.execute_reply":"2022-08-14T06:01:10.463001Z","shell.execute_reply.started":"2022-08-14T06:00:51.923713Z"},"id":"5SAsH5x73wYD","outputId":"cb24b89e-7376-491e-c78f-8997e95af1e2","papermill":{"duration":78.476414,"end_time":"2022-08-12T04:46:52.528073","exception":false,"start_time":"2022-08-12T04:45:34.051659","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n","\n","processor = Wav2Vec2Processor.from_pretrained(\"arijitx/wav2vec2-xls-r-300m-bengali\")\n","\n","# model = Wav2Vec2ForCTC.from_pretrained(\"Sameen53/cv_bn_bestModel_1\")\n","# model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-large-xlsr-53\", ctc_loss_reduction=\"mean\", pad_token_id=processor.tokenizer.pad_token_id, vocab_size=len(processor.tokenizer), gradient_checkpointing=True)\n","\n","# Load model from repo\n","#model = Wav2Vec2ForCTC.from_pretrained(\"myliew/Bengali_ASR\", use_auth_token=hugging_face_token)\n","\n","# Load model from local\n","model = Wav2Vec2ForCTC.from_pretrained(\"finetune_batch_2\")\n","# ;_;\n","#model = model.to(\"cuda\")\n"]},{"cell_type":"code","execution_count":151,"metadata":{"execution":{"iopub.execute_input":"2022-08-12T04:46:52.541151Z","iopub.status.busy":"2022-08-12T04:46:52.539576Z","iopub.status.idle":"2022-08-12T04:46:52.545686Z","shell.execute_reply":"2022-08-12T04:46:52.544816Z"},"id":"XATVgCLo6WC1","papermill":{"duration":0.014482,"end_time":"2022-08-12T04:46:52.547618","exception":false,"start_time":"2022-08-12T04:46:52.533136","status":"completed"},"tags":[]},"outputs":[],"source":["data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)"]},{"cell_type":"code","execution_count":152,"metadata":{},"outputs":[{"data":{"text/plain":["Wav2Vec2ForCTC(\n","  (wav2vec2): Wav2Vec2Model(\n","    (feature_extractor): Wav2Vec2FeatureEncoder(\n","      (conv_layers): ModuleList(\n","        (0): Wav2Vec2LayerNormConvLayer(\n","          (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,))\n","          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","          (activation): GELUActivation()\n","        )\n","        (1-4): 4 x Wav2Vec2LayerNormConvLayer(\n","          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,))\n","          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","          (activation): GELUActivation()\n","        )\n","        (5-6): 2 x Wav2Vec2LayerNormConvLayer(\n","          (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,))\n","          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","          (activation): GELUActivation()\n","        )\n","      )\n","    )\n","    (feature_projection): Wav2Vec2FeatureProjection(\n","      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      (projection): Linear(in_features=512, out_features=1024, bias=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): Wav2Vec2EncoderStableLayerNorm(\n","      (pos_conv_embed): Wav2Vec2PositionalConvEmbedding(\n","        (conv): Conv1d(1024, 1024, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)\n","        (padding): Wav2Vec2SamePadLayer()\n","        (activation): GELUActivation()\n","      )\n","      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","      (layers): ModuleList(\n","        (0-23): 24 x Wav2Vec2EncoderLayerStableLayerNorm(\n","          (attention): Wav2Vec2Attention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (feed_forward): Wav2Vec2FeedForward(\n","            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n","            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (output_dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","    )\n","  )\n","  (dropout): Dropout(p=0.0, inplace=False)\n","  (lm_head): Linear(in_features=1024, out_features=112, bias=True)\n",")"]},"execution_count":152,"metadata":{},"output_type":"execute_result"}],"source":["model"]},{"cell_type":"code","execution_count":153,"metadata":{"execution":{"iopub.execute_input":"2022-08-12T04:46:52.558812Z","iopub.status.busy":"2022-08-12T04:46:52.558530Z","iopub.status.idle":"2022-08-12T04:46:53.888933Z","shell.execute_reply":"2022-08-12T04:46:53.887910Z"},"id":"fLTYmime6Xsm","outputId":"4f82f4a8-a3de-40f4-e333-56a217cf3ebe","papermill":{"duration":1.338381,"end_time":"2022-08-12T04:46:53.891075","exception":false,"start_time":"2022-08-12T04:46:52.552694","status":"completed"},"tags":[]},"outputs":[],"source":["from datasets import load_metric\n","wer_metric = load_metric(\"wer\")"]},{"cell_type":"code","execution_count":154,"metadata":{"execution":{"iopub.execute_input":"2022-08-12T04:46:53.904135Z","iopub.status.busy":"2022-08-12T04:46:53.902334Z","iopub.status.idle":"2022-08-12T04:46:53.910509Z","shell.execute_reply":"2022-08-12T04:46:53.909638Z"},"id":"SLrCgqv56kVL","papermill":{"duration":0.016072,"end_time":"2022-08-12T04:46:53.912401","exception":false,"start_time":"2022-08-12T04:46:53.896329","status":"completed"},"tags":[]},"outputs":[],"source":["import numpy as np\n","def compute_metrics(pred):\n","    pred_logits = pred.predictions\n","    pred_ids = np.argmax(pred_logits, axis=-1)\n","\n","    pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id\n","\n","    pred_str = processor.batch_decode(pred_ids)\n","    # we do not want to group tokens when computing the metrics\n","    label_str = processor.batch_decode(pred.label_ids, group_tokens=False)\n","\n","    wer = wer_metric.compute(predictions=pred_str, references=label_str)\n","\n","    return {\"wer\": wer}"]},{"cell_type":"code","execution_count":155,"metadata":{"execution":{"iopub.execute_input":"2022-08-12T04:46:53.924544Z","iopub.status.busy":"2022-08-12T04:46:53.923732Z","iopub.status.idle":"2022-08-12T04:46:53.928733Z","shell.execute_reply":"2022-08-12T04:46:53.927862Z"},"id":"txL6Jp0D6vbb","papermill":{"duration":0.012952,"end_time":"2022-08-12T04:46:53.930655","exception":false,"start_time":"2022-08-12T04:46:53.917703","status":"completed"},"tags":[]},"outputs":[],"source":["model.freeze_feature_encoder()"]},{"cell_type":"code","execution_count":156,"metadata":{"execution":{"iopub.execute_input":"2022-08-12T04:46:53.944148Z","iopub.status.busy":"2022-08-12T04:46:53.943846Z","iopub.status.idle":"2022-08-12T04:46:58.183886Z","shell.execute_reply":"2022-08-12T04:46:58.182922Z"},"id":"p4-Al4Qy63OP","papermill":{"duration":4.250998,"end_time":"2022-08-12T04:46:58.186390","exception":false,"start_time":"2022-08-12T04:46:53.935392","status":"completed"},"tags":[]},"outputs":[],"source":["from transformers import TrainingArguments\n","\n","training_args = TrainingArguments(\n","  report_to=\"none\",\n","  hub_token = hugging_face_token,\n","  output_dir=\"myliew/Bengali_ASR\",\n","  group_by_length=True,\n","  per_device_train_batch_size=16,\n","  gradient_accumulation_steps=2,\n","  evaluation_strategy=\"steps\",\n","  num_train_epochs=7,\n","  gradient_checkpointing=True,\n","  save_steps=1500,\n","  eval_steps=1500,\n","  logging_strategy=\"epoch\",\n","  learning_rate=5e-7,\n","  weight_decay=0.0000025,\n","  warmup_steps=500,\n","  save_total_limit=3,\n","  resume_from_checkpoint=True,\n","  disable_tqdm=True,\n","#   load_best_model_at_end=True,\n","#   metric_for_best_model=\"wer\",  \n","# greater_is_better=False,\n",")"]},{"cell_type":"code","execution_count":157,"metadata":{"execution":{"iopub.execute_input":"2022-08-14T07:38:37.282846Z","iopub.status.busy":"2022-08-14T07:38:37.282480Z","iopub.status.idle":"2022-08-14T07:38:37.560132Z","shell.execute_reply":"2022-08-14T07:38:37.559124Z","shell.execute_reply.started":"2022-08-14T07:38:37.282822Z"},"id":"RQ7s8X-JwtOa","outputId":"34014125-52f2-49b8-b32b-fb6181a604a5","papermill":{"duration":835.799167,"end_time":"2022-08-12T05:00:53.990657","exception":false,"start_time":"2022-08-12T04:46:58.191490","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# from datasets import load_from_disk\n","\n","# dataset = load_from_disk(\"../input/cv-bn-train\")\n","\n","from datasets import load_from_disk\n","dataset = load_from_disk(\"train_subset_4_preprocessed_trimmed\")\n","# dataset = load_dataset(\"common_voice\",\"ab\")"]},{"cell_type":"code","execution_count":158,"metadata":{},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['audio', 'transcription', 'input_values', 'input_length', 'labels'],\n","        num_rows: 2515\n","    })\n","    test: Dataset({\n","        features: ['audio', 'transcription', 'input_values', 'input_length', 'labels'],\n","        num_rows: 444\n","    })\n","})"]},"execution_count":158,"metadata":{},"output_type":"execute_result"}],"source":["dataset"]},{"cell_type":"code","execution_count":159,"metadata":{"execution":{"iopub.execute_input":"2022-08-14T07:38:45.256706Z","iopub.status.busy":"2022-08-14T07:38:45.256393Z","iopub.status.idle":"2022-08-14T07:38:45.264940Z","shell.execute_reply":"2022-08-14T07:38:45.264273Z","shell.execute_reply.started":"2022-08-14T07:38:45.256682Z"},"papermill":{"duration":205.541663,"end_time":"2022-08-12T05:04:19.552843","exception":false,"start_time":"2022-08-12T05:00:54.011180","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# validation_dataset = load_from_disk(\"../input/commonvoicesbn2to9sec/validation_data\")\n"]},{"cell_type":"code","execution_count":160,"metadata":{"execution":{"iopub.execute_input":"2022-08-12T05:04:19.572609Z","iopub.status.busy":"2022-08-12T05:04:19.572258Z","iopub.status.idle":"2022-08-12T05:04:20.154967Z","shell.execute_reply":"2022-08-12T05:04:20.154064Z"},"papermill":{"duration":0.594779,"end_time":"2022-08-12T05:04:20.157137","exception":false,"start_time":"2022-08-12T05:04:19.562358","status":"completed"},"tags":[]},"outputs":[],"source":["# max_input_length_in_sec = 9.0\n","# dataset = dataset['train'].filter(lambda x: x < max_input_length_in_sec * 16000, input_columns=[\"input_length\"])\n","# min_input_length_in_sec = 1.0\n","# dataset = dataset.filter(lambda x: x > min_input_length_in_sec * 16000, input_columns=[\"input_length\"])"]},{"cell_type":"code","execution_count":161,"metadata":{"execution":{"iopub.execute_input":"2022-08-12T05:04:20.177281Z","iopub.status.busy":"2022-08-12T05:04:20.176992Z","iopub.status.idle":"2022-08-12T05:04:20.181134Z","shell.execute_reply":"2022-08-12T05:04:20.180156Z"},"papermill":{"duration":0.016357,"end_time":"2022-08-12T05:04:20.183213","exception":false,"start_time":"2022-08-12T05:04:20.166856","status":"completed"},"tags":[]},"outputs":[],"source":["# dataset = dataset.train_test_split(test_size=0.2, seed = 4 )"]},{"cell_type":"code","execution_count":162,"metadata":{"execution":{"iopub.execute_input":"2022-08-12T05:04:20.202600Z","iopub.status.busy":"2022-08-12T05:04:20.202330Z","iopub.status.idle":"2022-08-12T05:04:24.653494Z","shell.execute_reply":"2022-08-12T05:04:24.652457Z"},"id":"nolfu1ta63Yl","outputId":"40bcfbb7-038f-4497-aba6-de35143051ff","papermill":{"duration":4.463831,"end_time":"2022-08-12T05:04:24.656096","exception":false,"start_time":"2022-08-12T05:04:20.192265","status":"completed"},"tags":[]},"outputs":[],"source":["from transformers import Trainer\n","\n","trainer = Trainer(\n","    model=model,\n","    data_collator=data_collator,\n","    args=training_args,\n","    compute_metrics=compute_metrics,\n","    train_dataset=dataset['train'],\n","    eval_dataset=dataset['test'],\n","    tokenizer=processor.feature_extractor,\n",")"]},{"cell_type":"code","execution_count":163,"metadata":{"execution":{"iopub.execute_input":"2022-08-12T05:04:24.800113Z","iopub.status.busy":"2022-08-12T05:04:24.799334Z","iopub.status.idle":"2022-08-12T14:54:02.879438Z","shell.execute_reply":"2022-08-12T14:54:02.877919Z"},"id":"v8SJs8J1Aqhp","papermill":{"duration":35378.217754,"end_time":"2022-08-12T14:54:02.883949","exception":false,"start_time":"2022-08-12T05:04:24.666195","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\Moses\\anaconda3\\envs\\ml_audio\\Lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","c:\\Users\\Moses\\anaconda3\\envs\\ml_audio\\Lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:155: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.3583, 'learning_rate': 7.899999999999999e-08, 'epoch': 1.0}\n","{'loss': 0.3548, 'learning_rate': 1.5799999999999999e-07, 'epoch': 2.0}\n","{'loss': 0.3545, 'learning_rate': 2.3699999999999996e-07, 'epoch': 3.0}\n","{'loss': 0.3541, 'learning_rate': 3.1599999999999997e-07, 'epoch': 4.0}\n","{'loss': 0.3513, 'learning_rate': 3.95e-07, 'epoch': 5.0}\n","{'loss': 0.3523, 'learning_rate': 4.7399999999999993e-07, 'epoch': 6.0}\n","{'loss': 0.3396, 'learning_rate': 0.0, 'epoch': 7.0}\n","{'train_runtime': 97624.6124, 'train_samples_per_second': 0.18, 'train_steps_per_second': 0.006, 'train_loss': 0.3521233018871673, 'epoch': 7.0}\n"]},{"data":{"text/plain":["TrainOutput(global_step=553, training_loss=0.3521233018871673, metrics={'train_runtime': 97624.6124, 'train_samples_per_second': 0.18, 'train_steps_per_second': 0.006, 'train_loss': 0.3521233018871673, 'epoch': 7.0})"]},"execution_count":163,"metadata":{},"output_type":"execute_result"}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":142,"metadata":{"execution":{"iopub.execute_input":"2022-08-12T14:54:02.911527Z","iopub.status.busy":"2022-08-12T14:54:02.910288Z","iopub.status.idle":"2022-08-12T14:54:04.593126Z","shell.execute_reply":"2022-08-12T14:54:04.591799Z"},"papermill":{"duration":1.699052,"end_time":"2022-08-12T14:54:04.595763","exception":false,"start_time":"2022-08-12T14:54:02.896711","status":"completed"},"tags":[]},"outputs":[],"source":["#!rm -r ./myliew"]},{"cell_type":"code","execution_count":164,"metadata":{"execution":{"iopub.execute_input":"2022-08-12T14:54:04.623743Z","iopub.status.busy":"2022-08-12T14:54:04.622921Z","iopub.status.idle":"2022-08-12T14:57:48.602074Z","shell.execute_reply":"2022-08-12T14:57:48.600941Z"},"id":"IH-ES9ygA4VR","outputId":"678c3ab9-af46-4e38-ccbf-700b56cf1ece","papermill":{"duration":223.995835,"end_time":"2022-08-12T14:57:48.604342","exception":false,"start_time":"2022-08-12T14:54:04.608507","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\Moses\\.vscode\\Bengali_ASR\\myliew/Bengali_ASR is already a clone of https://huggingface.co/myliew/Bengali_ASR. Make sure you pull the latest changes with `repo.git_pull()`.\n","Upload file pytorch_model.bin: 1.18GB [47:26, 561kB/s]                            To https://huggingface.co/myliew/Bengali_ASR\n","   01f046e..349c006  main -> main\n","\n","Upload file pytorch_model.bin: 100%|██████████| 1.18G/1.18G [47:27<00:00, 443kB/s]\n","Upload file training_args.bin: 100%|██████████| 3.93k/3.93k [47:27<00:00, 1.41B/s] \n"]},{"data":{"text/plain":["'https://huggingface.co/myliew/Bengali_ASR/commit/349c006a199d19aade1b1a1ccba7e4a1ba53db5b'"]},"execution_count":164,"metadata":{},"output_type":"execute_result"}],"source":["trainer.push_to_hub()\n"]},{"cell_type":"code","execution_count":165,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Current Time = 13:46:27\n"]}],"source":["from datetime import datetime\n","\n","now = datetime.now()\n","\n","current_time = now.strftime(\"%H:%M:%S\")\n","print(\"Current Time =\", current_time)"]},{"cell_type":"code","execution_count":166,"metadata":{"papermill":{"duration":0.013209,"end_time":"2022-08-12T14:57:48.631002","exception":false,"start_time":"2022-08-12T14:57:48.617793","status":"completed"},"tags":[]},"outputs":[],"source":["trainer.save_model(\"finetune_batch_4\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":4}
